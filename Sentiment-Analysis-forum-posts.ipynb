{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "#user input\n",
    "url_link=input(\"Enter URL: \").rstrip()\n",
    "file_name=input(\"Name the file: \").rstrip() \n",
    "\n",
    "#create the csv with headers if csv does not already exist\n",
    "csv_file_path = pathlib.Path(file_name +'.csv')\n",
    "if csv_file_path.exists():\n",
    "    input(\"This csv already exists. Press Enter to append existing csv.\")\n",
    "else:\n",
    "    csv_header_df = pd.DataFrame(columns = ['Name', 'Date', 'Time', 'Score', 'Reply'])\n",
    "    csv_header_df.to_csv(csv_file_path, index = False, mode = \"a\", header=True, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "forum_thread_page_num = 1\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    url = url_link + 'page-' + str(forum_thread_page_num)\n",
    "    print(forum_thread_page_num)\n",
    "    request = requests.get(url)\n",
    "    response = request.text \n",
    "    soup = bs.BeautifulSoup(response, 'lxml')\n",
    "\n",
    "    #create list of usernames so that they can later be matched to comments \n",
    "    username_list = []\n",
    "    username = soup.findAll(\"a\", {\"itemprop\": \"name\"})\n",
    "    for name in username:\n",
    "        new_name = name.get_text()\n",
    "        username_list.append(new_name)\n",
    "        \n",
    "    #find the date & time\n",
    "    date_soup = soup.findAll('div', {'class': 'message-attribution-main'})\n",
    "    date_list = []\n",
    "    time_list = []\n",
    "    #date and time is found in the '<time>' tag. In the time tage there is a variable called \"datetime\" that is = to \n",
    "    #date of the post and formatted as '2020-09-24T18:28:56-0400', I store this datetime as a list object and slice it\n",
    "    #so that I get only '2020-09-24' for date and 18:28:56 for time.\n",
    "    for item in date_soup:\n",
    "        date = item.find('time').attrs['datetime'][0:10]\n",
    "        time_ = item.find('time').attrs['datetime'][11:19]\n",
    "        date_list.append(date)\n",
    "        time_list.append(time_)\n",
    "\n",
    "    #find the comments \n",
    "    comments = soup.findAll(\"div\", {\"class\": \"bbWrapper\"})\n",
    "\n",
    "    #return only the text from the comments. 'recursive=False' prevents parsing any sub-tags. All needed text is a \n",
    "    #direct child of -> \"div\", {\"class\": \"bbWrapper\"}\n",
    "    comment_list = []\n",
    "    for comment in comments:\n",
    "        comment=comment.find_all(text=True, recursive=False)\n",
    "        comment = ''.join(comment) #convert list to string\n",
    "        comment = comment.replace('\\n', '') #remove new lines for paragraphs(Combines multiple paragraphs to one)\n",
    "        if not comment: #if comment is empty\n",
    "            comment = 'N/A'\n",
    "        comment_list.append(comment)\n",
    "    \n",
    "    #use sentimentAnalyzer for each comment and create list of the 'compound' score for each comment\n",
    "    compound_result_list = []\n",
    "    for comment in comment_list:\n",
    "        sentiment_result_dict = sid.polarity_scores(comment)\n",
    "        compound_result = sentiment_result_dict.get('compound')\n",
    "        compound_result_list.append(compound_result)\n",
    "    \n",
    "    #Iterate through the compound_result list to determine whether each score is pos. neut. or neg. Then append this\n",
    "    #to the sentiment list\n",
    "    sentiment_list = []\n",
    "    for score in compound_result_list:\n",
    "        if score <= -0.05:\n",
    "            sentiment = \"Negative\"\n",
    "        elif score > -0.05 and score < 0.05:\n",
    "            sentiment = \"Neutural\"\n",
    "        elif score >= 0.05:\n",
    "            sentiment = \"Positive\"\n",
    "        sentiment_list.append(sentiment)\n",
    "\n",
    "    #-1 to -0.0500. The second bin is -0.0499 to 0.0499 The third bin is 0.0500 to 1\n",
    "    \n",
    "    #combine five lists and convert to DataFrame\n",
    "    new_dict = zip(username_list, date_list, time_list, compound_result_list, sentiment_list, comment_list)\n",
    "    df = DataFrame(new_dict)\n",
    "    df2 = df2.append(df)\n",
    "    \n",
    "    #if there are less than 50 usernames it means it is the last page and should break\n",
    "    if len(username_list) < 50:\n",
    "        #Rename the columns of the dataframe\n",
    "        df2.rename(columns={0: \"Username\", 1: \"Date\", 2: \"Time\", 3: \"Score\", 4:\"Sentiment\", 5: \"Replies\"}, inplace=True)\n",
    "        #Convert date & time columns from string to datetime objects so that they can be manipulated with pandas\n",
    "        df2[\"Date\"] = pd.to_datetime(df2[\"Date\"], format=\"%Y-%m-%d\")\n",
    "        df2[\"Time\"] = pd.to_datetime(df2[\"Time\"], format=\"%H:%M:%S\").dt.time\n",
    "\n",
    "        print('*FINISHED*')\n",
    "        \n",
    "        #####Total Replies by a user#####\n",
    "        #Use groupby to group by Username, then use .size() to return a series that will show\n",
    "        #the total number for each username. Convert this to a dataframe using .reset_index()\n",
    "        df3 = df2.groupby([\"Username\"]).size().reset_index(name='Total Replies') \n",
    "        #Sort the dataframe users with least replies to greatest replies then get the tail which will have users with the most posts. \n",
    "        #Do this because if the bar chart goes from gretest to least, the bar chart will be upside down.\n",
    "        df3.sort_values(by=['Total Replies'], inplace=True, ascending=True)\n",
    "        df3=df3.tail(10)\n",
    "        username_labels = df3[\"Username\"]\n",
    "        total_replies_label = df3[\"Total Replies\"]\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.barh(username_labels, total_replies_label)\n",
    "        plt.show()\n",
    "        ###########\n",
    "        \n",
    "        \n",
    "        #####Total Replies on a date in Chron order#####\n",
    "        #Group dates of the dataframe using groupby then find the total number of dates for each date using Grouper which will return a series. \n",
    "        #this series to a dataframe using .reset_index()\n",
    "        df4 = df2.set_index(\"Date\").groupby(pd.Grouper(freq='D')).size().reset_index(name='Total Replies')\n",
    "        date_labels = df4[\"Date\"]\n",
    "        total_replies_label=df4[\"Total Replies\"]\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.bar(date_labels, total_replies_label)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        ###########\n",
    "        \n",
    "        #####Sentiment neg, neut, pos#########\n",
    "        #groupby the sentiment column (pos. neg. neut.) add up each a create the total sentiment column\n",
    "        df5 = df2.groupby([\"Sentiment\"]).size().reset_index(name='Total Sentiment') \n",
    "        #Visualize Sentiment in pie chart\n",
    "        total_sentiment = df5[\"Total Sentiment\"]\n",
    "        sentiment_labels = [\"Negative\", \"Neutural\", \"Positive\"]\n",
    "        plt.pie(total_sentiment, labels = sentiment_labels, shadow = True, startangle = 90, autopct='%1.1f%%', radius = 3)\n",
    "        plt.show()\n",
    "        display(df5)\n",
    "        ##########\n",
    "         \n",
    "        #Write dataFrame to csv in append mode with the header removed\n",
    "        df2.to_csv(csv_file_path, index = False, mode = \"a\", header=False, encoding='utf-8-sig')\n",
    "\n",
    "        break\n",
    "    else:\n",
    "        forum_thread_page_num = forum_thread_page_num + 1\n",
    "\n",
    "#positive sentiment: compound score >= 0.05\n",
    "#neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "#negative sentiment: compound score <= -0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
