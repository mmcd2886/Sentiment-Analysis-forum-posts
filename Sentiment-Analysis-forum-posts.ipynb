{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "#Dataframes will be fully visible when printing\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", None)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "forum_thread_page_num = 1\n",
    "\n",
    "#User can enter which page to of thread to start collecting information on \n",
    "url_link = input(\"Enter URL for first page of thread: \").rstrip()\n",
    "file_name = input(\"Enter a name for the CSV file or leave blank to not save: \").rstrip() \n",
    "\n",
    "#User can enter which page of thread to start collecting infrmation on\n",
    "starting_page = input(\"Enter number for which page of thread to start on. Leave blank to start on first page of thread. \").rstrip()\n",
    "if starting_page != '':\n",
    "    starting_page = int(starting_page)\n",
    "    forum_thread_page_num = starting_page\n",
    "    \n",
    "#User can enter which page of thread to stop collecting infrmation on\n",
    "ending_page = input(\"Enter number for which page of thread to end on. Leave blank to end on last page of thread. \").rstrip()\n",
    "if ending_page == '':\n",
    "    ending_page = float('inf')\n",
    "else:\n",
    "    ending_page = int(ending_page)\n",
    "    \n",
    "#create the csv with headers if csv does not already exist\n",
    "csv_file_path = pathlib.Path(file_name +'.csv')\n",
    "if csv_file_path.exists():\n",
    "    input(\"This csv already exists. Press Enter to append existing csv or run script again and choose a different name.\")\n",
    "else:\n",
    "    csv_header_df = pd.DataFrame(columns = ['Name', 'Date_Time', 'Score', 'Quote', 'Sentiment', 'Reply'])\n",
    "    csv_header_df.to_csv(csv_file_path, index = False, mode = \"a\", header=True, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    url = url_link + 'page-' + str(forum_thread_page_num)\n",
    "    print(forum_thread_page_num)\n",
    "    print(url)\n",
    "    request = requests.get(url)\n",
    "    response = request.text \n",
    "    soup = bs.BeautifulSoup(response, 'lxml')\n",
    "\n",
    "    #create list of usernames so that they can later be matched to comments \n",
    "    username_list = []\n",
    "    username = soup.findAll(\"a\", {\"itemprop\": \"name\"})\n",
    "    for name in username:\n",
    "        new_name = name.get_text()\n",
    "        username_list.append(new_name)\n",
    "        \n",
    "    #find the date & time\n",
    "    date_soup = soup.findAll('div', {'class': 'message-attribution-main'})\n",
    "    date_time_list = []\n",
    "    #date and time is found in the '<time>' tag. In the time tage there is a variable called \"datetime\" that is = to \n",
    "    #date of the post and formatted as '2020-09-24T18:28:56-0400', I store this datetime as a list object and slice it\n",
    "    #so that I get only '2020-09-24 18:28:56 date_time.\n",
    "    for item in date_soup:\n",
    "        date_time = item.find('time').attrs['datetime'][0:19]\n",
    "        date_time_list.append(date_time)\n",
    "    #find the comments \n",
    "    comments = soup.findAll(\"div\", {\"class\": \"bbWrapper\"})\n",
    "\n",
    "    #Replies that quote other users will contain (\"div\", {\"class\": \"bbCodeBlock-expandContent\"}). If this is found\n",
    "    #'Quote' is added to the quote_reply_list Else: Not Quoted is addded to list. \n",
    "    #To access commment, return only the text from the comments. 'recursive=False' prevents parsing any sub-tags. All needed text is a \n",
    "    #direct child of -> \"div\", {\"class\": \"bbWrapper\"}\n",
    "    comment_list = []\n",
    "    quote_reply_list = []\n",
    "    for comment in comments:\n",
    "        replies_to_quotes = comment.find_all(\"div\", {\"class\": \"bbCodeBlock-expandContent\"})\n",
    "        if len(replies_to_quotes) > 0:\n",
    "            quoted_or_not = \"Quote\"\n",
    "        else:\n",
    "            quoted_or_not = \"Not Quoted\" \n",
    "        quote_reply_list.append(quoted_or_not)\n",
    "    \n",
    "        comment=comment.find_all(text=True, recursive=False)\n",
    "        comment = ''.join(comment) #convert list to string\n",
    "        comment = comment.replace('\\n', '') #remove new lines for paragraphs(Combines multiple paragraphs to one)\n",
    "        if not comment: #if comment is empty\n",
    "            comment = 'N/A'\n",
    "        comment_list.append(comment)\n",
    "\n",
    "    #use sentimentAnalyzer for each comment and create list of the 'compound' score for each comment\n",
    "    compound_result_list = []\n",
    "    for comment in comment_list:\n",
    "        sentiment_result_dict = sid.polarity_scores(comment)\n",
    "        compound_result = sentiment_result_dict.get('compound')\n",
    "        compound_result_list.append(compound_result)\n",
    "    \n",
    "    #Iterate through the compound_result list to determine whether each score is pos. neut. or neg. Then append this\n",
    "    #to the sentiment list\n",
    "    sentiment_list = []\n",
    "    for score in compound_result_list:\n",
    "        if score <= -0.05:\n",
    "            sentiment = \"Negative\"\n",
    "        elif score > -0.05 and score < 0.05:\n",
    "            sentiment = \"Neutural\"\n",
    "        elif score >= 0.05:\n",
    "            sentiment = \"Positive\"\n",
    "        sentiment_list.append(sentiment)\n",
    "    \n",
    "    #combine five lists and convert to DataFrame\n",
    "    new_dict = zip(username_list, date_time_list, compound_result_list, quote_reply_list, sentiment_list, comment_list)\n",
    "    df = DataFrame(new_dict)\n",
    "    df2 = df2.append(df)\n",
    "    \n",
    "    #if there are less than 50 usernames it means it is the last page and should break\n",
    "    if len(username_list) < 50 or forum_thread_page_num == ending_page:\n",
    "        #Rename the columns of the dataframe\n",
    "        df2.rename(columns={0: \"Username\", 1: \"Date_Time\", 2: \"Score\", 3: \"Quoted\", 4: \"Sentiment\", 5: \"Replies\"}, inplace=True)\n",
    "        #Convert date & time columns from string to datetime objects so that they can be manipulated with pandas\n",
    "        df2[\"Date_Time\"] = pd.to_datetime(df2[\"Date_Time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "           \n",
    "        print(\"\\n--------------------\\nTotal Replies: \", df2[\"Username\"].count(), \"\\n--------------------\")\n",
    "        \n",
    "        #####Total Replies on a date in Chron order#####  \n",
    "        #Groupby Day using freq='D' and then find the size() and add it to the column Total Replies which will tally the total replies for each day.\n",
    "        #convert the .size() series that it returns to a dataframe using .reset_index. Convert DateTime object to just date using strftime. if there is only one date worth of replies,\n",
    "        #use the if statement to group by hours instead to display hourly data for the single day. Else groupby day and show daily Total Replies.\n",
    "        df4 = df2.set_index(\"Date_Time\").groupby(pd.Grouper(freq='D')).size().reset_index(name='Total Replies')\n",
    "        df4[\"Date_Time\"] = (df4[\"Date_Time\"].dt.strftime('%Y-%m-%d'))\n",
    "        #This date will be the x-axis title if there is only one day of Replies\n",
    "        xlabel_date = str(df4[\"Date_Time\"][0])\n",
    "        if len(df4[\"Date_Time\"]) == 1:\n",
    "            df4 = df2.set_index(\"Date_Time\").groupby(pd.Grouper(freq='H')).size().reset_index(name='Total Replies')\n",
    "            df4[\"Date_Time\"] = (df4[\"Date_Time\"].dt.strftime('%H:%M:%S'))\n",
    "            #I am calling .plot on the Dataframe using pandas. This method references the Matplot API\n",
    "            df4.set_index(\"Date_Time\").plot.bar(figsize=(13, 8))\n",
    "            plt.xlabel(xlabel_date + \" (Hourly)\", fontsize=15)\n",
    "            plt.title(\"Total Replies by Hour\",fontsize=30, color=\"Black\")\n",
    "        else:\n",
    "            df4.set_index(\"Date_Time\").plot.bar(figsize=(13, 8))\n",
    "            plt.xlabel(\"Day\", fontsize=15)\n",
    "            plt.title(\"Total Replies by Day\",fontsize=30, color=\"Black\")\n",
    "        plt.ylabel(\"Total Replies\", fontsize=15)\n",
    "        plt.xticks(rotation=45)\n",
    "        #limit the number of x axis labels using 'nbins='\n",
    "        plt.locator_params(axis='x', nbins=13)\n",
    "        plt.show()\n",
    "        ###########\n",
    "        \n",
    "        #####Total Replies by a user#####\n",
    "        #Use groupby to group by Username, then use .size() to return a series that will show\n",
    "        #the total number for each username. Convert this to a dataframe using .reset_index()\n",
    "        df3 = df2.groupby([\"Username\"]).size().reset_index(name='Total Replies') \n",
    "        #Sort the dataframe users with least replies to greatest replies then get the tail which will have users with the most posts. \n",
    "        #Do this because if the bar chart goes from gretest to least, the bar chart will be upside down when plotted in matplot.\n",
    "        df3.sort_values(by=['Total Replies'], inplace=True, ascending=True)\n",
    "        df3 = df3.tail(15)\n",
    "        #matplot\n",
    "        fig, ax = plt.subplots(figsize=(13, 8))\n",
    "        ax.barh(df3[\"Username\"], df3[\"Total Replies\"])\n",
    "        plt.xlabel(\"Replies\", fontsize=15)\n",
    "        plt.ylabel(\"Username\", fontsize=15)\n",
    "        plt.title(\"Total Replies by Username\", fontsize=30)\n",
    "        plt.show()\n",
    "        ###########\n",
    "        ##Sentiment of top Users##\n",
    "#         for username in reversed(username_labels):\n",
    "#             individual_username_setniment_df = df2[\"\"]\n",
    "        \n",
    "        #####Sentiment neg, neut, pos#########\n",
    "        #groupby the sentiment column (pos. neg. neut.) add up each a create the total sentiment column\n",
    "        #Visualize Sentiment in pie chart\n",
    "        ###sentiment with and without quotes section##\n",
    "        sentiment_labels = [\"Negative\", \"Neutural\", \"Positive\"]\n",
    "        df_sentiment_with_quotes = df2.groupby([\"Sentiment\"]).size().reset_index(name=\"Total Sentiment\")  \n",
    "        total_sentiment_with_quotes = df_sentiment_with_quotes[\"Total Sentiment\"].tolist()\n",
    "        plt.pie(total_sentiment_with_quotes, labels = sentiment_labels, explode = (0, 0.2, 0), shadow = True, startangle = 90, autopct='%1.1f%%')\n",
    "        plt.title(\"Sentiment of all replies\", fontsize = 15)\n",
    "        plt.show()\n",
    "        display(df_sentiment_with_quotes) \n",
    "        \n",
    "        ##Sentiment with out quotes section##\n",
    "        #groupby the sentiment column (pos. neg. neut.) add up each a create the total sentiment column, but do no include replies\n",
    "        #that have quotes from other users in them because this could impact sentiment to the thread title\n",
    "        df_no_quotes = df2[df2[\"Quoted\"]==\"Not Quoted\"]\n",
    "        df_sentiment_no_quotes = df_no_quotes.groupby([\"Sentiment\"]).size().reset_index(name=\"Total Sentiment\") \n",
    "        total_sentiment_no_quotes = df_sentiment_no_quotes[\"Total Sentiment\"].tolist()\n",
    "        plt.pie(total_sentiment_no_quotes, labels = sentiment_labels, explode = (0, 0.2, 0), shadow = True, startangle = 90, autopct='%1.1f%%')\n",
    "        plt.title(\"Sentiment of replies that do not contain quotes\", fontsize = 15)\n",
    "        plt.show()\n",
    "        display(df_sentiment_no_quotes)\n",
    "        ##########\n",
    "         \n",
    "        #Write dataFrame to csv in append mode with the header removed\n",
    "        df2.to_csv(csv_file_path, index = False, mode = \"a\", header=False, encoding='utf-8-sig')\n",
    "        display(df2)\n",
    "        \n",
    "        break\n",
    "    else:\n",
    "        forum_thread_page_num = forum_thread_page_num + 1\n",
    "\n",
    "#positive sentiment: compound score >= 0.05\n",
    "#neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "#negative sentiment: compound score <= -0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
